{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fda26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861243b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation preprocessing pipeline\n",
    "valid_preprocess = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),  # Uniform image size\n",
    "    transforms.ToTensor(),  # Convert to PyTorch tensor\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),  # ImageNet mean\n",
    "        std=(0.229, 0.224, 0.225)    # ImageNet std\n",
    "    )\n",
    "])\n",
    "\n",
    "# Training augmentation pipeline\n",
    "train_augmentation = A.Compose([\n",
    "    A.Resize(height=224, width=224, always_apply=True),  # Ensure 224x224 size\n",
    "    A.HorizontalFlip(p=0.5),  # 50% chance of horizontal flip\n",
    "    A.Rotate(limit=(-20, 20), p=0.5),  # Random rotation up to Â±20 degrees\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),  # Brightness/contrast tweak\n",
    "    A.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),  # Standard normalization\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    ),\n",
    "    ToTensorV2()  # Convert to tensor for PyTorch\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b52a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 38\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation datasets\n",
    "training_data = datasets.ImageFolder(\n",
    "    root='data/train',\n",
    "    transform=train_augmentation  # Using augmentation pipeline for training\n",
    ")\n",
    "validation_data = datasets.ImageFolder(\n",
    "    root='data/valid',\n",
    "    transform=valid_preprocess   # Using preprocessing pipeline for validation\n",
    ")\n",
    "\n",
    "# Create data loaders for batching\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=training_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,  # Randomize training batches\n",
    "    num_workers=2  # Parallel data loading\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=validation_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # No shuffling for validation\n",
    "    num_workers=2  # Parallel data loading\n",
    ")\n",
    "\n",
    "# Determine number of unique classes\n",
    "total_classes = len(training_data.classes)\n",
    "print(f\"Number of classes: {total_classes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
